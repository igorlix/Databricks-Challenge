{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0597f8c0-3920-4931-900e-8e4cf8c50f2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Camada Gold\n",
    "Essa etapa contém dados agregados e otimizados para consultas e consumo por ferramentas de BI.\n",
    "\n",
    "## Objetivos:\n",
    "- Efetuei a leitura dos dados da tabela Delta da Camada Silver.\n",
    "\n",
    "- Criei tabelas agregadas por período (ano/mês), distrito e batalhão.\n",
    "\n",
    "- As tabelas Gold criadas estão no formato Delta e são gerenciadas pelo Unity Catalog.\n",
    "\n",
    "## Decisões Técnicas:\n",
    "- Novamente tentei me ater ao paralelismo, por isso as operações como _GroupBy_ (agrupamento) e _Agg_ (agregação) são executadas de forma paralela pelo Spark.\n",
    "\n",
    "-  As agregações são calculadas e armazenadas previamente em tabelas separadas.\n",
    "\n",
    "- Verifico se as tabelas agregadas existem antes de criá-las, se sim, mesclo os novos dados com *MERGE INTO*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fce9efa-2a31-4ea1-9cde-a0b4c883ebff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias para agregações\n",
    "from pyspark.sql.functions import col, count, sum, year, month, dayofmonth, to_date, lit, current_timestamp\n",
    "from pyspark.sql.types import LongType, DoubleType, StringType, DateType\n",
    "\n",
    "# Tabela Silver como fonte\n",
    "silver_table_name_full = \"`workspace`.`default`.`fire_incidents_silver`\"\n",
    "silver_table_name_simple = \"fire_incidents_silver\"\n",
    "\n",
    "# Tabelas Gold como destino\n",
    "gold_agg_by_time_full = \"`workspace`.`default`.`fire_incidents_gold_by_time`\"\n",
    "gold_agg_by_time_simple = \"fire_incidents_gold_by_time\"\n",
    "\n",
    "gold_agg_by_district_full = \"`workspace`.`default`.`fire_incidents_gold_by_district`\"\n",
    "gold_agg_by_district_simple = \"fire_incidents_gold_by_district\"\n",
    "\n",
    "gold_agg_by_battalion_full = \"`workspace`.`default`.`fire_incidents_gold_by_battalion`\"\n",
    "gold_agg_by_battalion_simple = \"fire_incidents_gold_by_battalion\"\n",
    "\n",
    "print(f\"Fonte de dados (Camada Silver): {silver_table_name_full}\")\n",
    "print(f\"Destino de dados (Gold - Por Tempo): {gold_agg_by_time_full}\")\n",
    "print(f\"Destino de dados (Gold - Por Distrito): {gold_agg_by_district_full}\")\n",
    "print(f\"Destino de dados (Gold - Por Batalhão): {gold_agg_by_battalion_full}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "818a04e7-4e96-473e-8fa2-29b2c5d60d21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lendo os dados da camada Silver\n",
    "print(f\"\\nLendo dados da Camada Silver ({silver_table_name_full})...\")\n",
    "\n",
    "silver_df = spark.table(silver_table_name_simple)\n",
    "\n",
    "print(\"Schema da Camada Silver (esperado com tipos corretos e nulos tratados):\")\n",
    "silver_df.printSchema()\n",
    "print(f\"Total de registros lidos da Camada Silver: {silver_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dd65ce5-8027-4b08-bcd5-0551492d650a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Agregações para a Camada Gold \n",
    "# Função auxiliar para gerar as strings SQL para UPDATE e INSERT no MERGE INTO\n",
    "def generate_merge_sql_strings(df_columns_list):\n",
    "\n",
    "    quoted_cols_for_sql = [f\"`{col_name}`\" for col_name in df_columns_list]\n",
    "    update_set_clauses = [f\"target.{col} = source.{col}\" for col in quoted_cols_for_sql]\n",
    "    update_set_sql_string = \",\\n    \".join(update_set_clauses)\n",
    "    insert_columns_sql_string = \", \".join(quoted_cols_for_sql)\n",
    "    insert_values_sql_string = \", \".join([f\"source.{col}\" for col in quoted_cols_for_sql])\n",
    "    return update_set_sql_string, insert_columns_sql_string, insert_values_sql_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b717f39-0a89-40fb-9410-21aaf52b62ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Agregação por Tempo \n",
    "print(\"\\nCriando agregação Gold por Tempo (Ano/Mês)\")\n",
    "\n",
    "# Garante que 'Incident Date' é do tipo Date\n",
    "silver_df_cleaned_dates = silver_df.withColumn(\"Incident Date\", col(\"Incident Date\").cast(DateType()))\n",
    "\n",
    "# Calcula as agregações\n",
    "gold_by_time_df_staged = silver_df_cleaned_dates.groupBy(year(col(\"Incident Date\")).alias(\"incident_year\"),\n",
    "                                                          month(col(\"Incident Date\")).alias(\"incident_month\")) \\\n",
    "                                                  .agg(count(\"ID\").alias(\"total_incidents\"),\n",
    "                                                       sum(\"Estimated Property Loss\").alias(\"total_property_loss\"),\n",
    "                                                       sum(\"Estimated Contents Loss\").alias(\"total_contents_loss\")) \\\n",
    "                                                  .withColumn(\"gold_loaded_at\", current_timestamp()) # Metadado de carga\n",
    "\n",
    "gold_by_time_df_staged.printSchema()\n",
    "print(f\"Total de registros no staging Gold (Por Tempo): {gold_by_time_df_staged.count()}\")\n",
    "\n",
    "# Prepara os dados para MERGE INTO\n",
    "gold_by_time_df_staged.createOrReplaceTempView(\"gold_by_time_staging\")\n",
    "\n",
    "# Gera as strings SQL para o MERGE INTO\n",
    "update_time_sql, insert_columns_time_sql, insert_values_time_sql = generate_merge_sql_strings(gold_by_time_df_staged.columns)\n",
    "\n",
    "#Cria a tabela Gold por Tempo se não existir\n",
    "print(f\"\\nVerificando e garantindo que a tabela Gold '{gold_agg_by_time_full}' exista com o schema correto\")\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {gold_agg_by_time_full}\") \n",
    "gold_by_time_df_staged.limit(0).write \\\n",
    "                      .format(\"delta\") \\\n",
    "                      .mode(\"overwrite\") \\\n",
    "                      .option(\"overwriteSchema\", \"true\") \\\n",
    "                      .option(\"delta.columnMapping.mode\", \"name\") \\\n",
    "                      .saveAsTable(gold_agg_by_time_simple)\n",
    "print(f\"Tabela Gold '{gold_agg_by_time_full}' criada/garantida com sucesso com o esquema correto.\")\n",
    "\n",
    "# Executa MERGE INTO para atualização incremental\n",
    "print(f\"\\nIniciando operação MERGE INTO para a tabela Gold '{gold_agg_by_time_full}'...\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  MERGE INTO {gold_agg_by_time_full} AS target\n",
    "  USING gold_by_time_staging AS source\n",
    "  ON target.incident_year = source.incident_year AND target.incident_month = source.incident_month\n",
    "  WHEN MATCHED THEN UPDATE SET\n",
    "    {update_time_sql}\n",
    "  WHEN NOT MATCHED THEN INSERT (\n",
    "    {insert_columns_time_sql}\n",
    "  )\n",
    "  VALUES (\n",
    "    {insert_values_time_sql}\n",
    "  )\n",
    "\"\"\")\n",
    "print(f\"MERGE INTO concluído para a tabela Gold '{gold_agg_by_time_full}'.\")\n",
    "print(\"A Camada Gold foi atualizada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5269ea98-7efd-4c29-8935-77a17e8c66e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Agregação por Distrito\n",
    "print(\"\\nCriando agregação Gold por Distrito\")\n",
    "\n",
    "gold_by_district_df_staged = silver_df.groupBy(col(\"neighborhood_district\").alias(\"district_name\")) \\\n",
    "                                 .agg(count(\"ID\").alias(\"total_incidents\"),\n",
    "                                      sum(\"Estimated Property Loss\").alias(\"total_property_loss\"),\n",
    "                                      sum(\"Estimated Contents Loss\").alias(\"total_contents_loss\")) \\\n",
    "                                 .withColumn(\"gold_loaded_at\", current_timestamp())\n",
    "\n",
    "print(\"\\nSchema da Tabela Gold\")\n",
    "gold_by_district_df_staged.printSchema()\n",
    "print(f\"Total de registros no staging Gold (Por Distrito): {gold_by_district_df_staged.count()}\")\n",
    "\n",
    "# Prepara dados para MERGE INTO\n",
    "gold_by_district_df_staged.createOrReplaceTempView(\"gold_by_district_staging\")\n",
    "\n",
    "# Gera as strings SQL para o MERGE INTO\n",
    "update_district_sql, insert_columns_district_sql, insert_values_district_sql = generate_merge_sql_strings(gold_by_district_df_staged.columns)\n",
    "\n",
    "# Cria a tabela Gold por Distrito \n",
    "print(f\"\\nVerificando e garantindo que a tabela Gold '{gold_agg_by_district_full}' exista com o schema correto\")\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {gold_agg_by_district_full}\") # Para depuração\n",
    "gold_by_district_df_staged.limit(0).write \\\n",
    "                   .format(\"delta\") \\\n",
    "                   .mode(\"overwrite\") \\\n",
    "                   .option(\"overwriteSchema\", \"true\") \\\n",
    "                   .option(\"delta.columnMapping.mode\", \"name\") \\\n",
    "                   .saveAsTable(gold_agg_by_district_simple)\n",
    "print(f\"Tabela Gold '{gold_agg_by_district_full}' criada/garantida com sucesso com o esquema correto.\")\n",
    "\n",
    "# Executa MERGE INTO para atualização incremental\n",
    "print(f\"\\nIniciando operação MERGE INTO para a tabela Gold '{gold_agg_by_district_full}'...\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  MERGE INTO {gold_agg_by_district_full} AS target\n",
    "  USING gold_by_district_staging AS source\n",
    "  ON target.district_name = source.district_name\n",
    "  WHEN MATCHED THEN UPDATE SET\n",
    "    {update_district_sql}\n",
    "  WHEN NOT MATCHED THEN INSERT (\n",
    "    {insert_columns_district_sql}\n",
    "  )\n",
    "  VALUES (\n",
    "    {insert_values_district_sql}\n",
    "  )\n",
    "\"\"\")\n",
    "print(f\"MERGE INTO concluído para a tabela Gold '{gold_agg_by_district_full}'.\")\n",
    "print(\"A Camada Gold (Por Distrito) foi atualizada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e0ad2b2-8f57-4956-94d5-93116e7df1ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Agregação por Batalhão\n",
    "print(\"\\nCriando agregação Gold por Batalhão.\")\n",
    "\n",
    "gold_by_battalion_df_staged = silver_df.groupBy(col(\"Battalion\").alias(\"battalion_id\")) \\\n",
    "                                 .agg(count(\"ID\").alias(\"total_incidents\"),\n",
    "                                      sum(\"Estimated Property Loss\").alias(\"total_property_loss\"),\n",
    "                                      sum(\"Estimated Contents Loss\").alias(\"total_contents_loss\")) \\\n",
    "                                 .withColumn(\"gold_loaded_at\", current_timestamp())\n",
    "\n",
    "print(\"\\nSchema da Tabela Gold (Por Batalhão - Staging):\")\n",
    "gold_by_battalion_df_staged.printSchema()\n",
    "print(f\"Total de registros por Batalhão: {gold_by_battalion_df_staged.count()}\")\n",
    "\n",
    "# Prepara os dados para MERGE INTO\n",
    "gold_by_battalion_df_staged.createOrReplaceTempView(\"gold_by_battalion_staging\")\n",
    "\n",
    "# Gera as strings SQL para o MERGE INTO\n",
    "update_battalion_sql, insert_columns_battalion_sql, insert_values_battalion_sql = generate_merge_sql_strings(gold_by_battalion_df_staged.columns)\n",
    "\n",
    "# Cria a tabela Gold por Batalhão\n",
    "print(f\"\\nVerificando e garantindo que a tabela Gold '{gold_agg_by_battalion_full}' exista com o schema correto\")\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {gold_agg_by_battalion_full}\") # Para depuração\n",
    "gold_by_battalion_df_staged.limit(0).write \\\n",
    "                    .format(\"delta\") \\\n",
    "                    .mode(\"overwrite\") \\\n",
    "                    .option(\"overwriteSchema\", \"true\") \\\n",
    "                    .option(\"delta.columnMapping.mode\", \"name\") \\\n",
    "                    .saveAsTable(gold_agg_by_battalion_simple)\n",
    "print(f\"Tabela Gold '{gold_agg_by_battalion_full}' criada/garantida com sucesso com o esquema correto.\")\n",
    "\n",
    "# MERGE INTO para atualização incremental\n",
    "print(f\"\\nIniciando operação MERGE INTO para a tabela Gold '{gold_agg_by_battalion_full}'...\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  MERGE INTO {gold_agg_by_battalion_full} AS target\n",
    "  USING gold_by_battalion_staging AS source\n",
    "  ON target.battalion_id = source.battalion_id\n",
    "  WHEN MATCHED THEN UPDATE SET\n",
    "    {update_battalion_sql}\n",
    "  WHEN NOT MATCHED THEN INSERT (\n",
    "    {insert_columns_battalion_sql}\n",
    "  )\n",
    "  VALUES (\n",
    "    {insert_values_battalion_sql}\n",
    "  )\n",
    "\"\"\")\n",
    "print(f\"MERGE INTO concluído para a tabela Gold '{gold_agg_by_battalion_full}'.\")\n",
    "print(\"A Camada Gold (Por Batalhão) foi atualizada.\")\n",
    "\n",
    "print(\"\\n--- Agregações da Camada Gold concluídas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b2325a3-1d54-4c61-b5c4-627adf75b85e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verificação Final das Tabelas Gold\n",
    "print(\"\\n--- Verificando a Tabela Gold: Por Tempo (Ano/Mês) ---\")\n",
    "final_gold_by_time_df = spark.table(gold_agg_by_time_simple)\n",
    "display(final_gold_by_time_df.orderBy(\"incident_year\", \"incident_month\").limit(10))\n",
    "\n",
    "print(\"\\n--- Verificando a Tabela Gold: Por Distrito ---\")\n",
    "final_gold_by_district_df = spark.table(gold_agg_by_district_simple)\n",
    "display(final_gold_by_district_df.orderBy(col(\"total_incidents\").desc()).limit(10))\n",
    "\n",
    "print(\"\\n--- Verificando a Tabela Gold: Por Batalhão ---\")\n",
    "final_gold_by_battalion_df = spark.table(gold_agg_by_battalion_simple)\n",
    "display(final_gold_by_battalion_df.orderBy(col(\"total_incidents\").desc()).limit(10))\n",
    "\n",
    "print(\"As tabelas agregadas estão prontas para consumo.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3-Camada_Gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
